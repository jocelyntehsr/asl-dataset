# American Sign Language (ASL) Dataset 

World Health Organization predicts that 1 in every 4 person will experience any form of hearing loss in 2050. Thus, the use of sign language is expected to increase over time. However, as of the current situation, deaf person needs a human sign language interpreter to communicate with the public. In the absence of the interpreter,  communication barrier is formed as majority of the public do not know sign language. Thus, this dataset aims to serve as the foundation for researchers to build AI models to make use of technology to fill the gap of human sign language interpreter. 


# About the dataset 

This is a dataset consists of MediaPipe Holistic landmark arrays for 30 American Sign Language (ASL) phrases. Under each phrase, there are 200 samples converted from videos. Within each sample, there are 30 arrays with (1662,0) values each.

Figure below illustrates the MediaPipe Holistic landmarks when a person signs "Hello". Note that this image only represents a frame, and each video sample has 30 frames.

![image](https://user-images.githubusercontent.com/84454650/227102662-d0f8be23-36fe-4c5c-914c-2124253af32d.png)

# Credits 

This dataset is established under the Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Malaysia.
